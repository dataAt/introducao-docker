# Docker `r emo::ji("whale")`

Docker é uma plataforma para o gerenciamento de *containers* (@Schommer2014), que ajuda desenvolvedores e administradores de sistemas a desenvolver, distribuir, implantar e executar aplicações em ambientes isolados, sem problemas com dependências do ambiente ou configurações através de Linux Containers (LXC) (@Schommer2014).

Ao utilizar o Docker, todos os problemas relacionados a instalação, configuração e solução de problemas relacionados a conflitos de dependências de um sistema são facilmente resolvidos. Atualmente o Docker vem sendo aplamente utilizado por sua facilidade de uso e baixa utilização de recursos computacionais para a implantação de sistemas e execução de algoritmos.

Todo o funcionamento do Docker é baseado em uma comunicação cliente-servidor, onde o cliente, através de uma API Rest envia comandos para o docker-daemon, que por sua vez representa o gerenciador de *containers* que realiza todas as operações e verificações necessárias para o funcionamento correto e simples do Docker. Esta estrutura é resumida na Figura abaixo.

<center>
![](res/2_docker/docker_api_infra.jpg){width=400px, height=400px}
</center>

A forma como fazemos a utilização da estrutura acima pode variar, já que se trata de uma API Rest, básicamente, qualquer linguagem de programação que suporte a comunicação através de protocolos de rede como HTTP conseguem se comunicar e interagir com o docker-daemon. Veja a Figura abaixo.

![](res/2_docker/docker_connect_api.svg)

Na Figura acima é possível entender como o processo de comunicação e interação com o docker-daemon funciona. O Cliente envia comandos através da API Rest, sendo que para esta já existem diversas ferramentas que consomem e facilitam o processo, como é o caso do próprio Docker CLI, que é uma ferramenta de linha de comando distribuida nas instalações padrão do Docker. O Servidor recebe as requisições e faz os tratamentos e operações equivalentes aos pedidos.

Este tipo de estrutura permite que, através de uma máquina seja feito o gerenciamento de vários servidores Docker, sem contar que, por ser uma API Rest, aplicações podem fazer interações com o servidor, o que facilita ainda mais a criação e disponibilização de ferramentas para o gerenciamento de *containers* através do Docker.

O ambiente do Docker, que como citado, é gerenciado pelo docker-daemon é constituido por três componentes principais (@Chung2016), sendo eles, Docker images e Dockerfiles, Docker registry e Docker containers. Cada um desses explicados nas subseções seguintes.

## Instalação

Agora com a visão geral de funcionamento do Docker, vamos fazer a instalação dele para começarmos a fazer sua utilização e entender os conceitos na prática! Por uma questão de facilidade, recomenda-se a utilização de um ambiente Linux. 

Os passos abaixo, apresentam a instalação do Docker no Linux Ubuntu (16.04 ou superior).

```
$ curl -fsSL https://get.docker.com -o get-docker.sh
$ sudo sh get-docker.sh
```

Caso você queira permitir a execução do Docker para usuários que não sejam *root* você pode executar o comando abaixo

```shell
$ sudo usermod -aG docker seu-usuario
```

> Caso você não execute o comando de permissão acima, todos os seus comandos do Docker deverão ser executados pelo root ou junto ao comando `sudo`.

Feito! A instalação do Docker já está pronta e funcionando na sua máquina, para testar execute o comando `docker -v`, o retorno deve ser algo parecido com isto

```shell
Docker version 18.09.7, build 2d0083d
```

O comando `docker` e todos os seus parâmetros representam a ferramenta Docker CLI, que foi citada anteriormente e já vem instalada na distribuição padrão do Docker.

Se você estiver utilizado uma outra plataforma que não a apresentada acima, você pode consultar o site do Docker ([https://docs.docker.com/install/](https://docs.docker.com/install/)) para verificar como prosseguir com a instalação.

## Containers

*Containers* são instâncias de Imagens Docker que estão sendo executadas em ambientes isolados, sendo que, nestes ambientes há todos os recursos necessários para a execução dos processos os quais foram definidos para os *containers*. Por exemplo, quando você quiser executar um *container* com o Postgres, ao realizar a execução, dentro do *container* já estará todas as bibliotecas necessárias para a execução do Postgres, inclusive os binários do banco propriamente dito.

## Imagens de containers

Como citado anteriormente, um *container* representa uma imagem Docker que está sendo executada. As imagens Docker, por sua vez, representam arquivos executáveis que possuem todo o descritivo de arquivos e execuções que devem ser feitos no momento em que a imagem é executada e passa a ser um *container*.

Com isto as imagens Docker é garantido que, todos os *containers* gerados através da mesma imagem sejam padronizados, tendo uma mesma estrutura.

### Criando imagens

A criação de imagens Docker é feita através da utilização de arquivos `Dockerfiles`, estes que descrevem qual será a estrutura das imagens e suas operações.

Dentro do `Dockerfile` existem diversas instruções para ditar cada caracteristica que deve ser empregada na imagem que está sendo gerada. 

Para você entender melhor, vamos criar um exemplo de uma imagem Docker que gera um *container* que executa um *script* Python.

Vamos começar criando o *script* Python, fazemos isto utilizando o comando abaixo

```shell
echo "print('Oi! Esta é minha primeira imagem Docker! E ela funciona!')" > ola.py
```

Com o *script*  criado, vamos criar um arquivo com o nome `Dockerfile`, dentro deste arquivo, vamos inserir o seguinte conteúdo. Não se preocupe se você não entender agora, cada uma das partes deste arquivo será explicada.

```shell
FROM python:3
COPY ola.py ./

CMD [ "./ola.py" ]
ENTRYPOINT [ "python" ]
```

Ao finalizar a edição do arquivo, vá até o diretório onde o arquivo está criado, e execute o comando `docker build`.

```shell
docker build -t "minha_primeira_imagem:1.0" .
```

Com este comando a sua imagem Docker será criada. Para verificar se ela realmente foi criada execute o comando `docker images`, que lista todas as imagens disponíveis para você utilizar. Ao digitar este comando você perceberá que há uma imagem com `REPOSITORY` de nome `minha_primeira_imagem`.

Para utilizar a imagem criada para gerar um container, vamos fazer a execução da imagem

```
docker run minha_primeira_imagem:1.0
```

> Caso queira apagar a imagem que criamos, utilize o comando `docker rmi` (docker rmi minha_primeira_imagem:1.0)

#### Entendendo o Dockerfile

Anteriormente foi visto um simples `Dockerfile`, que criou uma imagem para a execução de um *script* Python, vamos analisa-lo para entender o que foi feito.

Inicialmente no arquivo foi importado uma imagem com nome `python:3`, isto é feito com o comando `FROM`. Ou seja, sua imagem foi criada com base em uma outra imagem, esta que já possuia o Python 3 instalado.

Após a definição da imagem base, foi feito uma cópia do *script* para dentro do *container*, através do comando `COPY`. 

Por fim, os comandos `CMD` e `ENTRYPOINT` foram executados, e estes representam partes muito importantes de um `Dockerfile`, isto porque, normalmente um *container* é criado para executar um único processo, podendo este ser por exemplo, a inicialização de uma aplicação, ou a execução de um *script* , como fizemos.

A definição do processo que o *container* irá executar é feita através do comando `ENTRYPOINT`, ou seja, no nosso caso o processo principal será uma execução python, e o comando `CMD` faz o auxílio ao `ENTRYPOINT` já que, o `CMD` representam os parâmetros que serão passados para o `ENTRYPOINY`.

Existem muitas outras instruções que poderiam ser aplicadas neste `Dockerfile`, para saber mais sobre eles utilize a documentação do Docker ([https://docs.docker.com/engine/reference/builder/](https://docs.docker.com/engine/reference/builder/)).

#### Camadas de uma imagem

O Docker trabalha utilizando um conceito de camadas, onde cada modificação realizada por comandos do Dockerfile cria uma camada que não pode ser alterada, sendo possível alterar somente a última camada gerada.

> É importante entender o conceitos de camadas para que, suas imagens não fiquem grandes e com arquivos desnecessários.

Durante os testes de geração de imagens, ao executar o comando `docker buid`, várias informações foram exibidas, cada uma daquelas informações representam as camadas que estavam sendo criadas na imagem gerada.

Para entendermos melhor como as camadas funcionam, vamos criar um pequeno exemplo. Veja o seguinte `Dockerfile`.

```shell
FROM ubuntu

RUN apt update -y
RUN apt install vim -y

ENTRYPOINT [ "bash" ]
```

Ao executar o comando `docker build` com o `Dockerfile` acima, a seguinte estrutura de camadas será criada.

![](res/2_docker/camadas_1.svg)

Veja que, para cada comando foi criado uma camada, que por sua vêz tem um peso. Das camadas 1 a 4 nada mais pode ser alterado. Porém há um pequeno problema, quando o comando `apt update -y` foi executado *cache* foi criado e certamente não vai mais ser utilizado. O problema é que este *cache* ficou em uma camada *read-only* e não poderá mais ser modificado. Se o comando para limpar o *cache* for utilizado, a camada onde o *cache* está será copiada para o topo e então editada.

![](res/2_docker/camadas_2.svg)

Ou seja, mais uma camada foi criada, porém o *cache* ainda continua lá. Para resolve reste problema é preciso melhorar a forma como o `Dockerfile` foi criado, tentando executar tudo o que for possível em uma única camada, por exemplo.

```shell
FROM ubuntu

RUN apt update -y && apt install vim -y && apt clean

ENTRYPOINT [ "bash" ]
```

Com o `Dockerfile` acima, somente três camadas serão criadas, já que, toda a modificação para a instalação do `vim` é feita em uma única camada, que tem o *cache* removido.

<center>
![](res/2_docker/camadas_3.svg)
</center>

> Com isto é possível perceber a necessidade de otimizar os `Dockerfiles` e evitar camadas desnecessárias que só aumentam ocupam espaço

Para saber mais formas de otimização de `Dockerfiles`, consulte a documentação do Docker ([https://docs.docker.com/develop/develop-images/dockerfile_best-practices/](https://docs.docker.com/develop/develop-images/dockerfile_best-practices/)).

### Aquisição de imagens

Bem, mas existe alguma forma de eu compartilhar minhas imagens, ou mesmo utilizar alguma já feita pela comunidade, ou ao menos compartilhar meu Dockerfile? Sim! Você pode fazer isto através da utilização do registry! E você já fez a utilização deste serviço! Lembra na seção anterior durante a criação do `Dockerfile`? Então, ali existia uma instrução `FROM`, como explicado anteriormente, isso faz com que a sua imagem seja criada com base na imagem com o nome que você colocou, porém, se você lembrar foi inserido a seguinte instrução `FROM python:3`, bem, mas você não tem uma imagem na sua máquina com o nome `python:3`, ou pelo menos não tinha até a execução do comando ? E como o docker faz isso, ele utiliza o registry!

Quando pedimos a execução de uma imagem, ou mesmo a utilização dela para a criação de outra imagem, o docker-daemon busca esta imagem na sua máquina, caso não encontra, vai para o registry público, este nomeado de docker hub, lá, caso ele encontre a imagem com o nome e a tag que você definiu, ele baixa ela e utiliza na operação que você definiu.

<!-- 
Para ilustrar melhor, vejamos a figura abaixo, que apresenta a relação entre o dockerfile, a imagem e um container.
Inserir registry
![](res/docker_file_image_container.png) -->

<!-- Podemos buscar imagens do registry, este que é um repositório que aloca uma serie de images Docker [...] -->

## Arquitetura

Bem, agora que já conhecemos os principais componentes do ecossistema docker, vamos ampliar a imagem que apresenta a estrutura de funcionamento do docker cliente-servidor, naquele momento estavamos preocupados apenas em saber como nós, clientes docker, nos poderiamos nos comunicar com o docker deamon, porém agora sabemos bastante sobre o ambiente docker.

Vejamos a figura abaixo:

<!-- Será adaptado de: https://www.aquasec.com/wiki/display/containers/Docker+Architecture?preview=/2854889/2854891/Docker_Architecture.png -->
![](res/docker_arch.png)

Perceba que, o principio básico que já haviamos visto ainda está presente, onde através de uma API ou ferramenta de linha de comando (Que também utiliza a API) nos comunicamos com o *docker daemon*, porém agora podemos entender melhor que esta comunicação representa. Veja que, ao nos comunicarmos com o docker daemon, podemos criar e gerenciar imagens, ou mesmo baixa-las do registry e então criar *containers* a partir delas. Com isso temos um entendimento geral de como o docker trabalha, e agora podemos começar a fazer sua gerencia =D.

## Administrando containers
<!-- Agora que já sabemos o que são containers e sua relação com as imagens, vamos começar a entender como trabalhar com o gerenciamento de containers no Docker -->
<!-- Falar que, há ferramentas que podem ajudar no gerenciamento, uma delas é o portainer  -->

### Criando containers
Os comandos aqui listados já foram apresentados anteriormente, porém, foram colocados aqui apenas para reforçar o significado de cada um dos parâmetros inseridos

### Gerenciando as execuções de um container
<!-- docker create|run|stop|restart|start|unpause|rm -->

### Visualizando o status do container
<!-- docker stats|top|logs -->

### Gerenciamento de memória e CPU


### Armazenamento
<!-- data folder, volumes e container data-only -->

### Rede

## Um pouco mais sobre o ecossistema Docker `r emo::ji("octopus")`
