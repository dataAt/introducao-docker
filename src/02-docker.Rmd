# Docker `r emo::ji("whale")`

Docker é uma plataforma para o gerenciamento de *containers* (@Schommer2014), que ajuda desenvolvedores e administradores de sistemas a desenvolver, distribuir, implantar e executar aplicações em ambientes isolados, sem problemas com dependências do ambiente ou configurações através de Linux Containers (LXC) (@Schommer2014).

Ao utilizar o Docker, todos os problemas relacionados a instalação, configuração e solução de problemas relacionados a conflitos de dependências de um sistema são facilmente resolvidos. Atualmente o Docker vem sendo aplamente utilizado por sua facilidade de uso e baixa utilização de recursos computacionais para a implantação de sistemas e execução de algoritmos.

Todo o funcionamento do Docker é baseado em uma comunicação cliente-servidor, onde o cliente, através de uma API Rest envia comandos para o docker-daemon, que por sua vez representa o gerenciador de *containers* que realiza todas as operações e verificações necessárias para o funcionamento correto e simples do Docker. Esta estrutura é resumida na Figura abaixo.

<center>
![](res/2_docker/docker_api_infra.jpg){width=400px, height=400px}
</center>

A forma como fazemos a utilização da estrutura acima pode variar, já que se trata de uma API Rest, básicamente, qualquer linguagem de programação que suporte a comunicação através de protocolos de rede como HTTP conseguem se comunicar e interagir com o docker-daemon. Veja a Figura abaixo.

![](res/2_docker/docker_connect_api.svg)

Na Figura acima é possível entender como o processo de comunicação e interação com o docker-daemon funciona. O Cliente envia comandos através da API Rest, sendo que para esta já existem diversas ferramentas que consomem e facilitam o processo, como é o caso do próprio Docker CLI, que é uma ferramenta de linha de comando distribuida nas instalações padrão do Docker. O Servidor recebe as requisições e faz os tratamentos e operações equivalentes aos pedidos.

Este tipo de estrutura permite que, através de uma máquina seja feito o gerenciamento de vários servidores Docker, sem contar que, por ser uma API Rest, aplicações podem fazer interações com o servidor, o que facilita ainda mais a criação e disponibilização de ferramentas para o gerenciamento de *containers* através do Docker.

O ambiente do Docker, que como citado, é gerenciado pelo docker-daemon é constituido por três componentes principais (@Chung2016), sendo eles, Docker images e Dockerfiles, Docker registry e Docker containers. Cada um desses explicados nas subseções seguintes.

## Instalação

Agora com a visão geral de funcionamento do Docker, vamos fazer a instalação dele para começarmos a fazer sua utilização e entender os conceitos na prática! Por uma questão de facilidade, recomenda-se a utilização de um ambiente Linux. 

Os passos abaixo, apresentam a instalação do Docker no Linux Ubuntu (16.04 ou superior).

```
$ curl -fsSL https://get.docker.com -o get-docker.sh
$ sudo sh get-docker.sh
```

Caso você queira permitir a execução do Docker para usuários que não sejam *root* você pode executar o comando abaixo

```shell
$ sudo usermod -aG docker seu-usuario
```

> Caso você não execute o comando de permissão acima, todos os seus comandos do Docker deverão ser executados pelo root ou junto ao comando `sudo`.

Feito! A instalação do Docker já está pronta e funcionando na sua máquina, para testar execute o comando `docker -v`, o retorno deve ser algo parecido com isto

```shell
Docker version 18.09.7, build 2d0083d
```

O comando `docker` e todos os seus parâmetros representam a ferramenta Docker CLI, que foi citada anteriormente e já vem instalada na distribuição padrão do Docker.

Se você estiver utilizado uma outra plataforma que não a apresentada acima, você pode consultar o site do Docker ([https://docs.docker.com/install/](https://docs.docker.com/install/)) para verificar como prosseguir com a instalação.

## Containers

*Containers* são instâncias de Imagens Docker que estão sendo executadas em ambientes isolados, sendo que, nestes ambientes há todos os recursos necessários para a execução dos processos os quais foram definidos para os *containers*. Por exemplo, quando você quiser executar um *container* com o Postgres, ao realizar a execução, dentro do *container* já estará todas as bibliotecas necessárias para a execução do Postgres, inclusive os binários do banco propriamente dito.

## Imagens de containers

Como citado anteriormente, um *container* representa uma imagem Docker que está sendo executada. As imagens Docker, por sua vez, representam arquivos executáveis que possuem todo o descritivo de arquivos e execuções que devem ser feitos no momento em que a imagem é executada e passa a ser um *container*.

Com isto as imagens Docker é garantido que, todos os *containers* gerados através da mesma imagem sejam padronizados, tendo uma mesma estrutura.

### Criando imagens

A criação de imagens Docker é feita através da utilização de arquivos `Dockerfiles`, estes que descrevem qual será a estrutura das imagens e suas operações.

Dentro do `Dockerfile` existem diversas instruções para ditar cada caracteristica que deve ser empregada na imagem que está sendo gerada. 

Para você entender melhor, vamos criar um exemplo de uma imagem Docker que gera um *container* que executa um *script* Python.

Vamos começar criando o *script* Python, fazemos isto utilizando o comando abaixo

```shell
echo "print('Oi! Esta é minha primeira imagem Docker! E ela funciona!')" > ola.py
```

Com o *script*  criado, vamos criar um arquivo com o nome `Dockerfile`, dentro deste arquivo, vamos inserir o seguinte conteúdo. Não se preocupe se você não entender agora, cada uma das partes deste arquivo será explicada.

```shell
FROM python:3
COPY ola.py ./

CMD [ "./ola.py" ]
ENTRYPOINT [ "python" ]
```

Ao finalizar a edição do arquivo, vá até o diretório onde o arquivo está criado, e execute o comando `docker build`.

```shell
docker build -t "minha_primeira_imagem:1.0" .
```

Com este comando a sua imagem Docker será criada. Para verificar se ela realmente foi criada execute o comando `docker images`, que lista todas as imagens disponíveis para você utilizar. Ao digitar este comando você perceberá que há uma imagem com `REPOSITORY` de nome `minha_primeira_imagem`.

Para utilizar a imagem criada para gerar um container, vamos fazer a execução da imagem

```
docker run minha_primeira_imagem:1.0
```

> Caso queira apagar a imagem que criamos, utilize o comando `docker rmi` (docker rmi minha_primeira_imagem:1.0)

#### Entendendo o Dockerfile

Anteriormente foi visto um simples `Dockerfile`, que criou uma imagem para a execução de um *script* Python, vamos analisa-lo para entender o que foi feito.

Inicialmente no arquivo foi importado uma imagem com nome `python:3`, isto é feito com o comando `FROM`. Ou seja, sua imagem foi criada com base em uma outra imagem, esta que já possuia o Python 3 instalado.

Após a definição da imagem base, foi feito uma cópia do *script* para dentro do *container*, através do comando `COPY`. 

Por fim, os comandos `CMD` e `ENTRYPOINT` foram executados, e estes representam partes muito importantes de um `Dockerfile`, isto porque, normalmente um *container* é criado para executar um único processo, podendo este ser por exemplo, a inicialização de uma aplicação, ou a execução de um *script* , como fizemos.

A definição do processo que o *container* irá executar é feita através do comando `ENTRYPOINT`, ou seja, no nosso caso o processo principal será uma execução python, e o comando `CMD` faz o auxílio ao `ENTRYPOINT` já que, o `CMD` representam os parâmetros que serão passados para o `ENTRYPOINY`.

Existem muitas outras instruções que poderiam ser aplicadas neste `Dockerfile`, para saber mais sobre eles utilize a documentação do Docker ([https://docs.docker.com/engine/reference/builder/](https://docs.docker.com/engine/reference/builder/)).

#### Camadas de uma imagem

O Docker trabalha utilizando um conceito de camadas, onde cada modificação realizada por comandos do Dockerfile cria uma camada que não pode ser alterada, sendo possível alterar somente a última camada gerada.

> É importante entender o conceitos de camadas para que, suas imagens não fiquem grandes e com arquivos desnecessários.

Durante os testes de geração de imagens, ao executar o comando `docker buid`, várias informações foram exibidas, cada uma daquelas informações representam as camadas que estavam sendo criadas na imagem gerada.

Para entendermos melhor como as camadas funcionam, vamos criar um pequeno exemplo. Veja o seguinte `Dockerfile`.

```shell
FROM ubuntu

RUN apt update -y
RUN apt install vim -y

ENTRYPOINT [ "bash" ]
```

Ao executar o comando `docker build` com o `Dockerfile` acima, a seguinte estrutura de camadas será criada.

![](res/2_docker/camadas_1.svg)

Veja que, para cada comando foi criado uma camada, que por sua vêz tem um peso. Das camadas 1 a 4 nada mais pode ser alterado. Porém há um pequeno problema, quando o comando `apt update -y` foi executado *cache* foi criado e certamente não vai mais ser utilizado. O problema é que este *cache* ficou em uma camada *read-only* e não poderá mais ser modificado. Se o comando para limpar o *cache* for utilizado, a camada onde o *cache* está será copiada para o topo e então editada.

![](res/2_docker/camadas_2.svg)

Ou seja, mais uma camada foi criada, porém o *cache* ainda continua lá. Para resolve reste problema é preciso melhorar a forma como o `Dockerfile` foi criado, tentando executar tudo o que for possível em uma única camada, por exemplo.

```shell
FROM ubuntu

RUN apt update -y && apt install vim -y && apt clean

ENTRYPOINT [ "bash" ]
```

Com o `Dockerfile` acima, somente três camadas serão criadas, já que, toda a modificação para a instalação do `vim` é feita em uma única camada, que tem o *cache* removido.

<center>
![](res/2_docker/camadas_3.svg)
</center>

> Com isto é possível perceber a necessidade de otimizar os `Dockerfiles` e evitar camadas desnecessárias que só ocupam espaço

Para saber mais formas de otimização de `Dockerfiles`, consulte a documentação do Docker ([https://docs.docker.com/develop/develop-images/dockerfile_best-practices/](https://docs.docker.com/develop/develop-images/dockerfile_best-practices/)).

### Aquisição de imagens

Além da criação de imagens é possível fazer a aquisição de imagens já criadas pela comunidade, ou mesmo distribuída por algum instituto ou empresa com seus sistemas já configurados e prontos para a execução.

Para isso o Docker Registry pode ser utilizado, este que é um componente que está dentro da plataforma Docker e que facilita muito a sua utilização. Estes componentes podem ser públicos e disponível para todos, como o caso do [Dockerhub](https://hub.docker.com/) ou privado, específico para empresas e institutos, por exemplo.

Por fazer parte da plataforma, o registry já está integrado ao funcionamento do docker-daemon. Vamos fazer alguns testes para entender. Utilize o comando `docker images` para listar as imagens que estão em sua máquina.

Você provavelmente só terá a imagem criada anteriormente (Isso se você não excluíu ela). Vamos então tentar executar uma imagem que não está na sua máquina.

```shell
docker run centos:7
```

Mesmo você não tendo a imagem nomeada `centos:7` em sua máquina o comando está sendo executado, isso porque o docker-daemon, por padrão, ao não encontrar em sua máquina verifica no registry público Docker hub e verifica se tem uma imagem com o nome que você inseriu, caso tenha ele baixa para dai executar o comando inserido. Veja a Figura.

![](res/2_docker/docker_registry.svg)

Durante os passos da criação do [Dockerfile](#criando-imagens) essa *feature* foi utilizada, ao inserir a imagem de nome `python:3` na instrução `FROM` do `Dockerfile`, o `docker-daemon` verifica se há a imagem na máquina, como não tinha ele baixou para então continuar a criação da imagem.

## Arquitetura

Com todos os componentes já conhecidos, há a possibilidade da expansão da visão geral de toda a estrutura e funcionamento do Docker. Inicialmente haviamos definido somente a forma de comunicação entre o cliente-servidor, porém agora com todos os conceitos que já vimos, vamos olhar como todo o ambiente Docker está integrado, para isto veja a Figura abaixo.

<!-- Será adaptado de: https://www.aquasec.com/wiki/display/containers/Docker+Architecture?preview=/2854889/2854891/Docker_Architecture.png -->
![](res/2_docker/docker_arch.png)

> É possível perceber toda a ligação entre cada um dos componentes apresentados até aqui.

Com isso estamos prontos para iniciar as atividades práticas com o Docker e o gerenciamento de *containers*.

## Administrando containers

Esta seção apresenta exemplos para a administração de *containers* através da utilização do Docker CLI.

### Criando containers

Vamos começar com exemplos das diferentes formas de criação de *container*. Começando com a criação básica de um *container* do Debian.

```
docker create debian
```

Depois de criar, utilize o comando `docker ps -a` para listar todos os *containers* criados. Quando você listar, vai ver várias informações sobre o *container* criado, como por exemplo a imagem que ele utilizou, o ID, se há portas de rede abertas e o nome. Por padrão, não é necessário definir o nome do *container*, mas é recomendado que o faça, então vamos excluir o *container* criado e gerar um novo com um nome definido.

```shell
# Excluíndo container
docker rm ID_DO_CONTAINER_CRIADO

# Criando um novo container de nome exemplo_debian
docker create --name exemplo_debian debian
```

Ao listar novamente todos os *containers* você vai ver que lá está o novo *container*, com o nome que foi definido no comando anterior. O *container* ainda não está sendo executado, uma vez que definimos que ele deveria apenas ser criado, vamos então executar ele com o comando `docker start`.

```shell
docker start exemplo_debian
```

Ele foi executado, para listar somente os *containers* que estão sendo executados, utilize o comando `docker ps`, sem qualquer outro parâmetro.

Sua listagem estará vazia já que o *container* do Debian está configurado para executar o comando `bash`, então, ao iniciarmos o *container* ele executou o comando e em seguida finalizou, se quisermos manter o *container* ligado, devemos definir que ele terá um terminal interativo, para isto no momento da criação, os parâmetros `-ti` devem ser passados. Vamos lá então, excluir o que haviamos criado e gerar ele novamente com os novos parâmetros


```shell
# Excluíndo container exemplo_debian
docker rm exemplo_debian

# Gerando um novo container que trabalha em segundo plano
docker create -ti --name exemplo_debian debian

# Executando o novo container criado
docker start exemplo_debian
```

Ao executar os comandos o novo *container* já estará sendo executado, para verificar, liste novamente os *containers* em execução. Vamos agora acessar o container criado, para isto usamos o comando `docker attach`, que recupera o `bash` do *container* caso ele não esteja executando outro processo.

```
docker attach exemplo_debian
```

> Em outros cenários o `bash` pode não estar disponível, então ao invês do `docker attach` pode ser utilizado o `docker exec` ([https://docs.docker.com/engine/reference/commandline/exec/](https://docs.docker.com/engine/reference/commandline/exec/))

Ao executar o comando, você já estará dentro do terminal do *container* criado. Como dito anteriormente, este ambiente é isolado de sua máquina, então faça testes, navegue entre os diretórios, para você ver que é uma instância completamente isolada. Para sair do terminal e não finalizar o *container* utilize os seguintes botões de seu teclado: `CTRL + p + q`. Ao listar novamente os *containers* em execução, lá estará ele sendo executado.

Nos exemplos anteriores criavamos o *container* depois faziamos sua execução, porém podemos já criar um *container* e imediatamente realizar sua inicialização, para isto utilizamos o comando `docker run`, que recebe os mesmos parâmetros que o `docker create`, com a diferença de que ele executa o *container* após sua criação.

```
docker run -ti --name exemplo_debian debian
```

> Executando o comando acima, o *containewr* irá iniciar e você já estará em seu `bash`.

### Gerenciando as execuções de um container
<!-- docker create|run|stop|restart|start|unpause|rm -->

### Visualizando o status do container
<!-- docker stats|top|logs -->

### Gerenciamento de memória e CPU


### Armazenamento
<!-- data folder, volumes e container data-only -->

### Rede

## Um pouco mais sobre o ecossistema Docker `r emo::ji("octopus")`
